{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import (Dense, Conv1D)\n",
    "from keras.models import Sequential\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "id": "_OENIgutwjp1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the natural language understanding dataset and BERT model\n",
    "\n",
    "Clone the repos inside intent-detection directory\n",
    "```\n",
    "git clone https://github.com/tilde-nlp/NLU-datasets.git\n",
    "git clone https://huggingface.co/bert-base-multilingual-cased\n",
    "```\n",
    "\n",
    "Directory tree should be as follows\n",
    "```\n",
    "/intent-detection\n",
    "├── NLU-datasets\n",
    "├── bert-base-multilingual-cased\n",
    "├── run-on-windows.ipynb\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_file(path: str) -> List[str]:\n",
    "    \"\"\" Read path and append each line without \\n as an element to an array.\n",
    "    Encoding is specified to correctly read files in Russian.\n",
    "    Example output: ['FindConnection', 'FindConnection', ..., 'FindConnection']\n",
    "    \"\"\"\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        array = []\n",
    "        for line in list(f):\n",
    "            array.append(line.split('\\n')[0])\n",
    "        return array\n",
    "\n",
    "\n",
    "def get_source_text(dataset_type: str, source_language: str = None, labels: bool = False, machine_translated: bool = False) -> List[str]:\n",
    "    \"\"\" Wrapper for read_file that provides file path.\n",
    "    Prompts in all languages are in the same order, therefore they use the same label files. So please be careful\n",
    "    to use the correct argument for labels, as label=True returns labels regardless of specified source_language\n",
    "    Usage examples:\n",
    "    prompts: read_source_text(\"test\", \"et\", False)\n",
    "    labels: read_source_text(\"test\")\n",
    "    :param dataset_type: \"test\" or \"train\"\n",
    "    :param source_language: \"lv\", \"ru\", \"et\", \"lt\"\n",
    "    :param labels: does the file being read contain labels\n",
    "    :return: array of file contents for specified file\n",
    "    \"\"\"\n",
    "    if labels:\n",
    "        return read_file(f\"NLU-datasets\\chatbot\\chatbot_{dataset_type}_ans.txt\")\n",
    "    elif machine_translated:\n",
    "        return read_file(f\"machine-translated-datasets\\{source_language}_{dataset_type}.txt\")\n",
    "    else:\n",
    "        return read_file(f\"NLU-datasets\\chatbot\\{source_language}\\chatbot_{dataset_type}_q.txt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the NLU-datasets in their original source languages\n",
    "\n",
    "en_test = get_source_text(\"test\", \"en\")\n",
    "lv_test = get_source_text(\"test\", \"lv\")\n",
    "ru_test = get_source_text(\"test\", \"ru\")\n",
    "et_test = get_source_text(\"test\", \"et\")\n",
    "lt_test = get_source_text(\"test\", \"lt\")\n",
    "\n",
    "en_train = get_source_text(\"train\", \"en\")\n",
    "lv_train = get_source_text(\"train\", \"lv\")\n",
    "ru_train = get_source_text(\"train\", \"ru\")\n",
    "et_train = get_source_text(\"train\", \"et\")\n",
    "lt_train = get_source_text(\"train\", \"lt\")\n",
    "\n",
    "train_answers = get_source_text(dataset_type=\"train\", labels=True)\n",
    "test_answers = get_source_text(dataset_type=\"test\", labels=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert len(train_answers) == len(en_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read non-English NLU-datasets that have been pre-machine-translated to English\n",
    "\n",
    "lv_test_en = get_source_text(\"test\", \"lv\", machine_translated=True)\n",
    "ru_test_en = get_source_text(\"test\", \"ru\", machine_translated=True)\n",
    "et_test_en = get_source_text(\"test\", \"et\", machine_translated=True)\n",
    "lt_test_en = get_source_text(\"test\", \"lt\", machine_translated=True)\n",
    "\n",
    "lv_train_en = get_source_text(\"train\", \"lv\", machine_translated=True)\n",
    "ru_train_en = get_source_text(\"train\", \"ru\", machine_translated=True)\n",
    "et_train_en = get_source_text(\"train\", \"et\", machine_translated=True)\n",
    "lt_train_en = get_source_text(\"train\", \"lt\", machine_translated=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(lv_test[0])\n",
    "print(lv_test_en[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definitions\n",
    "## Model and tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"bert-base-multilingual-cased\" # loading from huggingface\n",
    "model_name = \"./bert-base-multilingual-cased\" # loading from local path\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model_bert = TFBertModel.from_pretrained(model_name)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDWtw2FHxDOl",
    "outputId": "d583acfa-dc0e-465b-bd41-e5f2bc4477e3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# use keras.to_categorical() instead\n",
    "def encode_labels(answers: List) -> List:\n",
    "    \"\"\" Encode labels in one hot-encoding\n",
    "    'FindConnection' corresponds to [[1, 0]]\n",
    "    'DepartureTime' corresponds to [[0, 1]]\n",
    "    \"\"\"\n",
    "    y = []\n",
    "    for answer in answers:\n",
    "        if answer == 'FindConnection':\n",
    "            y.append([[1, 0]])\n",
    "        else:\n",
    "            y.append([[0, 1]])\n",
    "    return y"
   ],
   "metadata": {
    "id": "wB3HbmHb2Ugq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoded_train_labels = encode_labels(train_answers)\n",
    "encoded_train_labels = tf.convert_to_tensor(encoded_train_labels)\n",
    "\n",
    "encoded_test_labels = encode_labels(test_answers)\n",
    "encoded_test_labels = tf.convert_to_tensor(encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model_one_layer(sentence_length: int, units: int = 2, hidden_size: int = 768):\n",
    "    \"\"\"\n",
    "    returns <tf.Tensor: shape=(1, 1, units), dtype=float32>\n",
    "    e.g. <tf.Tensor: shape=(1, 1, 2), dtype=float32>\n",
    "    where 2 = units\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(sentence_length, hidden_size)))\n",
    "    model.add(Dense(units, activation='softmax'))\n",
    "    model.add(Conv1D(units, sentence_length, padding=\"valid\", activation=\"softmax\"))\n",
    "    model.add(Dense(units, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_adam_optimizer(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0, epsilon=None, amsgrad=False):\n",
    "    # TODO: Replace legacy optimizer with current version of Adam\n",
    "    return tf.keras.optimizers.legacy.Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, decay=decay, amsgrad=amsgrad)\n",
    "\n",
    "\n",
    "\n",
    "def get_classification_model(learning_rate: int, sentence_length: int):\n",
    "    optimizer = create_adam_optimizer(lr=learning_rate)\n",
    "    classification_model = create_model_one_layer(sentence_length=sentence_length)\n",
    "\n",
    "    classification_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return classification_model\n",
    "\n",
    "\n",
    "def plot_performance(data, dataset: str, x_label: str = 'accuracy'):\n",
    "    plt.plot(data)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel(x_label)\n",
    "    plt.title(f\"{dataset} model {x_label}\")\n",
    "    plt.savefig(f\"{dataset}-{x_label}.png\")\n",
    "    # plt.savefig(f\"{dataset}{x_label}.pdf\", dpi=150) # pdf for LaTeX\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def training(train_dataset, dataset_name: str, learning_rate: int, sentence_length: int, labels):\n",
    "\n",
    "    classification_model = get_classification_model(learning_rate, sentence_length)\n",
    "\n",
    "    encoded_input = tokenizer(train_dataset, padding='max_length', max_length=sentence_length, truncation=True, return_tensors='tf')\n",
    "    classification_input = model_bert(encoded_input)[\"last_hidden_state\"]\n",
    "\n",
    "    history = classification_model.fit(classification_input, y=labels, batch_size=batch_size, epochs=number_of_epochs)\n",
    "    # predictions = classification_model(classification_input)\n",
    "\n",
    "    plot_performance(history.history['accuracy'], dataset=dataset_name, x_label='accuracy')\n",
    "    plot_performance(history.history['loss'], dataset=dataset_name, x_label='loss')\n",
    "\n",
    "    return classification_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_classification_model(classification_model, en_test, encoded_test_labels):\n",
    "    encoded_input = tokenizer(en_test, padding='max_length', max_length=sentence_length, truncation=True, return_tensors='tf')\n",
    "    classification_input = model_bert(encoded_input)[\"last_hidden_state\"]\n",
    "\n",
    "    test_loss, test_accuracy = classification_model.evaluate(classification_input, encoded_test_labels, batch_size=batch_size)\n",
    "    print('Test Loss: {}'.format(test_loss))\n",
    "    print('Test Accuracy: {}'.format(test_accuracy))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A small example\n",
    "## Sentence -> word embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "sentence_length = 20\n",
    "\n",
    "text = en_train[0:batch_size]\n",
    "encoded_input = tokenizer(text, padding='max_length', max_length=sentence_length, truncation=True, return_tensors='tf')\n",
    "encoded_input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# odict_keys(['last_hidden_state', 'pooler_output'])\n",
    "inputs = model_bert(encoded_input)[\"last_hidden_state\"]\n",
    "inputs.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word embedding -> classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = create_adam_optimizer(lr=0.03)\n",
    "classification_model = create_model_one_layer(sentence_length=sentence_length)\n",
    "\n",
    "classification_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# initial probabilities\n",
    "classification_model(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model.fit(inputs, y=encoded_train_labels[0:batch_size], epochs=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# view the output of the classification_model: probabilities for labels\n",
    "\n",
    "classification_model(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "sentence_length = 20\n",
    "learning_rate = 0.0003\n",
    "number_of_epochs = 150"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Each language has its own model\n",
    "### Using the original NLU-datasets\n",
    "#### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_en = training(en_train, dataset_name=\"en_train\", learning_rate=learning_rate, sentence_length=sentence_length, labels=encoded_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_lv = training(lv_train, dataset_name=\"lv_train\", learning_rate=learning_rate, sentence_length=sentence_length, labels=encoded_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_ru = training(ru_train, dataset_name=\"ru_train\", learning_rate=learning_rate, sentence_length=sentence_length, labels=encoded_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_et = training(et_train, dataset_name=\"et_train\", learning_rate=learning_rate, sentence_length=sentence_length, labels=encoded_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_lt = training(lt_train, dataset_name=\"lt_train\", learning_rate=learning_rate, sentence_length=sentence_length, labels=encoded_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_en, en_test, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_lv, lv_test, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_ru, ru_test, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_et, et_test, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_lt, lt_test, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using machine translated non-English datasets\n",
    "#### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_lv_en = training(lv_train_en, dataset_name=\"lv_train_en\", learning_rate=learning_rate, sentence_length=sentence_length, labels=encoded_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_ru_en = training(ru_train_en, dataset_name=\"ru_train_en\", learning_rate=learning_rate, sentence_length=sentence_length, labels=encoded_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_et_en = training(et_train_en, dataset_name=\"et_train_en\", learning_rate=learning_rate, sentence_length=sentence_length, labels=encoded_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_lt_en = training(lt_train_en, dataset_name=\"lt_train_en\", learning_rate=learning_rate, sentence_length=sentence_length, labels=encoded_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_lv_en, lv_test_en, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_ru_en, ru_test_en, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_et_en, et_test_en, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_lt_en, lt_test_en, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One model trained on all languages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# one big train label dataset\n",
    "all_train_labels = []\n",
    "\n",
    "for i in range(5):\n",
    "    all_train_labels.extend(train_answers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# one big test label dataset\n",
    "all_test_labels = []\n",
    "\n",
    "for i in range(5):\n",
    "    all_test_labels.extend(test_answers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_train_labels = encode_labels(all_train_labels)\n",
    "all_train_labels = tf.convert_to_tensor(all_train_labels)\n",
    "\n",
    "all_test_labels = encode_labels(all_test_labels)\n",
    "all_test_labels = tf.convert_to_tensor(all_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using the original NLU-datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# one big training dataset\n",
    "all_train = []\n",
    "all_train.extend(en_train)\n",
    "all_train.extend(lv_train)\n",
    "all_train.extend(ru_train)\n",
    "all_train.extend(et_train)\n",
    "all_train.extend(lt_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# one big test dataset\n",
    "all_test = []\n",
    "all_test.extend(en_test)\n",
    "all_test.extend(lv_test)\n",
    "all_test.extend(ru_test)\n",
    "all_test.extend(et_test)\n",
    "all_test.extend(lt_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_all = training(all_train, dataset_name=\"all_train\", learning_rate=learning_rate, sentence_length=sentence_length, labels=all_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_all, all_test, all_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using machine translated non-English datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# one big training dataset\n",
    "all_train_en = []\n",
    "all_train_en.extend(en_train)\n",
    "all_train_en.extend(lv_train_en)\n",
    "all_train_en.extend(ru_train_en)\n",
    "all_train_en.extend(et_train_en)\n",
    "all_train_en.extend(lt_train_en)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# one big test dataset\n",
    "all_test_en = []\n",
    "all_test_en.extend(en_test)\n",
    "all_test_en.extend(lv_test_en)\n",
    "all_test_en.extend(ru_test_en)\n",
    "all_test_en.extend(et_test_en)\n",
    "all_test_en.extend(lt_test_en)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_all = training(all_train_en, dataset_name=\"all_train_en\", learning_rate=learning_rate, sentence_length=sentence_length, labels=all_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_all, all_test_en, all_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trained only on English data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_model_en = training(en_train, dataset_name=\"en_train\", learning_rate=learning_rate, sentence_length=sentence_length, labels=encoded_train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test on non-English data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_en, lv_test, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_en, ru_test, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_en, et_test, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_en, lt_test, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test on non-English machine translated to English data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_en, lv_test_en, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_en, ru_test_en, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_en, et_test_en, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_classification_model(classification_model_en, lt_test_en, encoded_test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
