{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import (Dense, Conv1D)\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import BertTokenizer, TFBertModel"
   ],
   "metadata": {
    "id": "_OENIgutwjp1"
   },
   "execution_count": 77,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the natural language understanding dataset and BERT model\n",
    "\n",
    "Clone the repos inside intent-detection directory\n",
    "```\n",
    "git clone https://github.com/tilde-nlp/NLU-datasets.git\n",
    "git clone https://huggingface.co/bert-base-multilingual-cased\n",
    "```\n",
    "\n",
    "Directory tree should be as follows\n",
    "```\n",
    "/intent-detection\n",
    "├── NLU-datasets\n",
    "├── bert-base-multilingual-cased\n",
    "├── run-on-windows.ipynb\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "if \"NLU-datasets\" not in os.getcwd():\n",
    "    os.chdir(\"./NLU-datasets\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def get_data(path: str) -> List[str]:\n",
    "    \"\"\" Read path and append each line without \\n as an element to an array.\n",
    "    Encoding is specified to correctly read files in Russian.\n",
    "    Example output: ['FindConnection', 'FindConnection', ..., 'FindConnection']\n",
    "    \"\"\"\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        array = []\n",
    "        for line in list(f):\n",
    "            array.append(line.split('\\n')[0])\n",
    "        return array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'DepartureTime', 'FindConnection', 'FindConnection', 'DepartureTime', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'FindConnection', 'DepartureTime', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'DepartureTime', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'DepartureTime', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'DepartureTime', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'FindConnection', 'DepartureTime', 'DepartureTime', 'FindConnection', 'FindConnection', 'DepartureTime', 'FindConnection', 'FindConnection']\n"
     ]
    }
   ],
   "source": [
    "path_list = Path(\"chatbot\").glob(\"**/*.txt\")\n",
    "\n",
    "for path in path_list:\n",
    "    # because path is object not string\n",
    "    path_in_str = str(path)\n",
    "    # print(path_in_str)\n",
    "    if path_in_str == \"chatbot\\chatbot_train_ans.txt\":\n",
    "        train_answers = get_data(path_in_str)\n",
    "    elif path_in_str == \"chatbot\\chatbot_test_ans.txt\":\n",
    "        test_answers  = get_data(path_in_str)\n",
    "    elif path_in_str == \"chatbot\\en\\chatbot_test_q.txt\":\n",
    "        en_test  = get_data(path_in_str)\n",
    "    elif path_in_str == \"chatbot\\en\\chatbot_train_q.txt\":\n",
    "        en_train  = get_data(path_in_str)\n",
    "    elif path_in_str == \"chatbot\\lv\\chatbot_test_q.txt\":\n",
    "        lv_test  = get_data(path_in_str)\n",
    "    elif path_in_str == \"chatbot\\lv\\chatbot_train_q.txt\":\n",
    "        lv_train  = get_data(path_in_str)\n",
    "    elif path_in_str == \"chatbot\\\\ru\\chatbot_test_q.txt\":\n",
    "        ru_test  = get_data(path_in_str)\n",
    "    elif path_in_str == \"chatbot\\\\ru\\chatbot_train_q.txt\":\n",
    "        ru_train  = get_data(path_in_str)\n",
    "    elif path_in_str == \"chatbot\\et\\chatbot_test_q.txt\":\n",
    "        et_test  = get_data(path_in_str)\n",
    "    elif path_in_str == \"chatbot\\et\\chatbot_train_q.txt\":\n",
    "        et_train  = get_data(path_in_str)\n",
    "    elif path_in_str == \"chatbot\\lt\\chatbot_test_q.txt\":\n",
    "        lt_test  = get_data(path_in_str)\n",
    "    elif path_in_str == \"chatbot\\lt\\chatbot_train_q.txt\":\n",
    "        lt_train  = get_data(path_in_str)\n",
    "\n",
    "\n",
    "print(train_answers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zver\\ws\\intent-detection\n"
     ]
    }
   ],
   "source": [
    "if \"NLU-datasets\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# define model and tokenizer\n",
    "model_name = \"bert-base-multilingual-cased\" # loading from huggingface\n",
    "model_name = \"./bert-base-multilingual-cased\" # loading from local path\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model_bert = TFBertModel.from_pretrained(model_name)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDWtw2FHxDOl",
    "outputId": "d583acfa-dc0e-465b-bd41-e5f2bc4477e3"
   },
   "execution_count": 83,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at ./bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing word embeddings on small example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# test the tokenizer\n",
    "multiple_lines = [\n",
    "'i want to go marienplatz',\n",
    "'when is the next train in muncher freiheit?',\n",
    "'when does the next u-bahn leaves from garching forschungszentrum?'\n",
    "]\n",
    "ids_for_test = tokenizer(multiple_lines, padding=True, return_tensors='tf')\n",
    "ids_for_test"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogq1bdseEHhl",
    "outputId": "da6b6b8c-e752-4362-8c77-cfd08e49d2df"
   },
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': <tf.Tensor: shape=(3, 19), dtype=int32, numpy=\narray([[   101,    177,  21528,  10114,  11783,  24538,  10136,  20732,\n           102,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0],\n       [   101,  10841,  10124,  10105,  13451,  17767,  10106, 101833,\n         13396,  42109,  15543,    136,    102,      0,      0,      0,\n             0,      0,      0],\n       [   101,  10841,  15107,  10105,  13451,    189,    118,  15688,\n         15797,  24516,  10188,  47243,  41247,  10142,  12044,  10716,\n         72100,    136,    102]])>, 'token_type_ids': <tf.Tensor: shape=(3, 19), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(3, 19), dtype=int32, numpy=\narray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>}"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# test the model\n",
    "model_bert_output = model_bert(ids_for_test)"
   ],
   "metadata": {
    "id": "w4RzE1OpIMDk"
   },
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(model_bert_output.keys())\n",
    "\n",
    "input_dimensions = model_bert_output['last_hidden_state'].shape\n",
    "input_dimensions"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uirRKwL5dJoW",
    "outputId": "2c62d2da-dd57-4729-c662-f8fa9cd507d2"
   },
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['last_hidden_state', 'pooler_output'])\n"
     ]
    },
    {
     "data": {
      "text/plain": "TensorShape([3, 19, 768])"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "multiple_labels = [\n",
    " 'FindConnection\\n',\n",
    " 'DepartureTime\\n',\n",
    " 'DepartureTime\\n'\n",
    "]\n",
    "multiple_labels_for_training = tf.convert_to_tensor([0, 1, 1])\n",
    "print(multiple_labels_for_training)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2kt-Q3yf2NR",
    "outputId": "d95e3493-5f62-4fb5-dc20-8bd8275e0dc1"
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 1], shape=(3,), dtype=int32)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "assert len(test_answers) == len(en_test)"
   ],
   "metadata": {
    "id": "YAdAGm3lyq1u"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "sentence_length = 20\n",
    "\n",
    "text = en_test[0:batch_size]\n",
    "encoded_input = tokenizer(text, padding='max_length', max_length=sentence_length, truncation=True, return_tensors='tf')\n",
    "inputs = model_bert(encoded_input)[\"last_hidden_state\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 20, 768), dtype=float32, numpy=\narray([[[-0.08018287,  0.03810783,  0.27046824, ...,  0.39124072,\n         -0.11388035, -0.04561067],\n        [-0.13535435, -0.6108816 ,  0.83754337, ...,  0.60649425,\n         -0.3622976 ,  0.06997238],\n        [-0.9340399 , -0.27897757,  0.34910378, ...,  1.0008135 ,\n         -0.27053413,  0.39220405],\n        ...,\n        [-0.12981133, -0.3453001 ,  0.6919307 , ...,  0.47795454,\n         -0.35215393,  0.29598516],\n        [-0.20455204, -0.32787555,  0.87851584, ...,  0.687666  ,\n         -0.5359596 ,  0.26696217],\n        [-0.5047288 , -0.10888059,  0.11342178, ...,  0.54780823,\n         -0.33753088,  0.34957582]],\n\n       [[-0.06291284,  0.3134947 ,  0.05111048, ...,  0.65492725,\n          0.06485228, -0.05769763],\n        [-0.33032477,  0.5593583 ,  0.24920447, ...,  0.6845547 ,\n          0.11658497, -0.09617171],\n        [-0.27714643,  0.38922876, -0.20803127, ...,  0.6321562 ,\n          0.16640294,  0.09471501],\n        ...,\n        [-0.27393073,  0.46105814,  0.26216924, ...,  0.530871  ,\n         -0.04223691,  0.14786337],\n        [-0.30779555,  0.4253151 ,  0.18591176, ...,  0.40252548,\n         -0.07205404,  0.10971968],\n        [-0.23843387,  0.4651582 ,  0.21947758, ...,  0.5706693 ,\n          0.02339889,  0.01104108]],\n\n       [[ 0.05952393,  0.07034901,  0.1647277 , ...,  0.46774244,\n          0.18229014,  0.01124709],\n        [-0.21076398,  0.3608988 ,  0.28080636, ...,  0.73379874,\n          0.31069234,  0.02694985],\n        [ 0.34621823,  0.06715591,  0.82106936, ...,  0.973297  ,\n         -0.12897079,  0.03388727],\n        ...,\n        [-0.29822767,  0.38781416,  0.21935718, ...,  0.6944201 ,\n         -0.00117162, -0.00827033],\n        [-0.11802271,  0.24875008,  0.4153418 , ...,  0.32137126,\n          0.31338054, -0.09541713],\n        [-0.15069707,  0.19805336,  0.37451252, ...,  0.65636593,\n          0.13858262, -0.02285973]],\n\n       [[-0.21978495, -0.29888698,  0.31093422, ...,  0.40437505,\n          0.26552027, -0.28337437],\n        [-0.60417736, -1.1451885 ,  1.0141463 , ...,  0.48306948,\n          0.3517396 , -0.31730425],\n        [-0.11432634, -0.91909134,  0.6387234 , ..., -0.09346914,\n          0.01510193, -1.0701079 ],\n        ...,\n        [-0.31358126, -0.7169875 ,  0.49346107, ...,  0.21518238,\n          0.23997971, -0.27938703],\n        [-0.2787477 , -0.71088004,  0.45756412, ...,  0.19604182,\n          0.2929837 , -0.36888114],\n        [-0.6992927 , -0.7224568 ,  0.7981561 , ...,  0.300545  ,\n         -0.2654241 , -0.5828961 ]]], dtype=float32)>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model_one_layer(units, **kwargs):\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.Input(shape=(batch_size, sentence_length, 768))) # from shape=(1, 9, 768)\n",
    "    model.add(Dense(units, activation='softmax'))\n",
    "    model.add(Conv1D(units, sentence_length, padding=\"valid\", activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "def create_adam_optimizer(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False):\n",
    "    return Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, amsgrad=amsgrad)\n",
    "\n",
    "learning_rate = 0.03\n",
    "optimizer = create_adam_optimizer(lr=learning_rate)\n",
    "classification_model = create_model_one_layer(units=2) # units = 2 because we want to get scores for two classes"
   ],
   "metadata": {
    "id": "wB3HbmHb2Ugq"
   },
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 4, 1, 2), dtype=float32, numpy=\narray([[[[0.21387655, 0.78612345]],\n\n        [[0.1751532 , 0.8248468 ]],\n\n        [[0.13610135, 0.86389863]],\n\n        [[0.20202312, 0.7979769 ]]]], dtype=float32)>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.compile(optimizer=optimizer,\n",
    "              #loss='categorical_crossentropy',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# expand dimensions\n",
    "classifiaction_input = tf.expand_dims(inputs, axis=0)\n",
    "\n",
    "# view the output of the classification_model\n",
    "# probabilities for labels\n",
    "classification_model(classifiaction_input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
